scale_color_brewer(type = "qual", palette = 3)
? imap
kmeans(data, centers = 5)
kmeans(data, centers = 5)$centers
kmeans(data, centers = 5)$cluster
data %>%
mutate(
cluster = kmeans(data, centers = 5, nstart = 100)$cluster,
cluster = factor(cluster) # for discrete color scale
) %>%
ggplot(aes(x1, x2, color = cluster)) +
geom_point() +
coord_equal()
factor(kmeans(data, centers = 5)$cluster)
# elbow plot:
K_max <- 10
TWSS <- vector(length = K_max)
for (K in 1:K_max) {
TWSS[K] <- kmeans(data, centers = K, nstart = 100)$tot.withinss
}
tibble(K = 1:10, TWSS = TWSS) %>%
ggplot(aes(K, TWSS)) +
geom_line() +
geom_point()
knitr::opts_chunk$set(
comment = "#", fig.height = 3,
cache = FALSE,  collapse = TRUE,
error = TRUE
)
library("tidyverse"); theme_set(theme_minimal())
theme_update(panel.grid.minor = element_blank())
library("lubridate")
eml_data <- read_csv(
file = "C:/Users/koesl/Documents/Baylor/2020/CSI 2300-01/dataset/EML_through_09_12_2019.csv",
col_types = cols(
"Date-Time" = col_datetime(format = "%m/%d/%y %H:%M"))) %>%
select(-1) %>% # delete col 1
set_names(str_to_lower) %>% # lower case
rename("time" = "date-time") %>%
rename("do_sat" = "dosat")
glimpse(eml_data)
shallow_eml_data <- eml_data %>%
filter(depth <= 1) %>%
mutate(weeks = week(time))
glimpse(shallow_eml_data)
mod_do <- shallow_eml_data %>%
lm(ph~ do, data = .)
summary(mod_do)
mod_do_cond_wk<- shallow_eml_data %>%
lm(ph~do + cond + weeks, data = .)
summary(mod_do_cond_wk)
ggplot(data = shallow_eml_data, aes(x = do, y = ph)) +
geom_point(alpha = 0.25)
ggplot(data = shallow_eml_data, aes(x = cond, y = ph)) +
geom_point(alpha = 0.25)
#Note: similar result even
ggplot(data = shallow_eml_data, aes(x = weeks, y = ph)) +
geom_point(alpha = 0.25)
data_predict <- tibble(cond = c(340, 340),
do = c(7, 7),
weeks = c(37, 38)) %>%
predict(mod_do_cond_wk, .)
#also works:
# new.data<-tibble(cond=c(340,340), do=c(7,7), week=c(37,38))
# mod_do_cond_wk %>% predict(new.data)
library("tidymodels")
# augment(mod_do) # the .fitted is the yhat, or the predicted value.
# note: what this shows is that the mod_do itself carries the data to recreate the model
mod_do %>%
augment() %>%
ggplot(aes(x = do, y = ph)) +
geom_point() +
geom_line(aes(x = do, y = .fitted), color = "blue") # regression line of the predicted model
mod_do %>%
augment() %>%
ggplot(aes(x = do, y = .resid)) +
geom_point(aes(color = shallow_eml_data$weeks))
set.seed(5)
n <- 100
df1 <- MASS::mvrnorm(50, c(0, 0), diag(2)) %>%
as.data.frame() %>% as_tibble() %>%
set_names(c("x1", "x2")) %>%
mutate("y" = 0)
df2 <- MASS::mvrnorm(40, c(1.5, 1.5), diag(2)) %>%
as.data.frame() %>% as_tibble() %>%
set_names(c("x1", "x2")) %>%
mutate("y" = 1)
df3 <- MASS::mvrnorm(10, c(-2, 0), .25*diag(2)) %>%
as.data.frame() %>% as_tibble() %>%
set_names(c("x1", "x2")) %>%
mutate("y" = 1)
(data <- bind_rows(df1, df2, df3) %>%
mutate(y = factor(y)))
ggplot(data, aes(x1, x2, color = y))+
geom_point(size = 3)
expand_grid(x1 = 1:2, x2 = 3:4)
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(y ~ x1 + x2, data = data) # two inputs, x1 and x2
glm(y ~ poly(x1, 3) + poly(x2, 3), data = data, family = binomial()) %>%
augment() %>%
glimpse()
mesh <- expand_grid(x1 = seq(-3, 4.5, length.out = 100),
x2 = seq(-3, 4.5, length.out = 100))
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(y ~ x1 + x2 + poly(x1, 3)+ poly(x2, 3), data = data) %>% # poly to degree 3 is the x^3 function
predict(mesh) %>%
bind_cols(mesh, .) %>%  # attach column of prediction based on x1 and x2 to mesh
ggplot(aes(x1, x2)) +
geom_raster(aes(fill = .pred_class), alpha = 0.2) + # fill each pixel on the grid base on predicted value
geom_point(data = data, aes(color = y))
precip <- read_rds("C:/Users/koesl/Documents/Baylor/2020/CSI 2300-01/dataset/precip-precip.rds")
glimpse(precip)
data
expand_grid(x1 = 1:2, x2 = 3:4)
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(y ~ x1 + x2, data = data) # two inputs, x1 and x2
glm(y ~ poly(x1, 3) + poly(x2, 3), data = data, family = binomial()) %>%
augment() %>%
glimpse()
mesh <- expand_grid(x1 = seq(-3, 4.5, length.out = 100),
x2 = seq(-3, 4.5, length.out = 100))
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(y ~ x1 + x2 + poly(x1, 3)+ poly(x2, 3), data = data) %>% # poly to degree 3 is the x^3 function
predict(mesh) %>%
bind_cols(mesh, .) %>%  # attach column of prediction based on x1 and x2 to mesh
ggplot(aes(x1, x2)) +
geom_raster(aes(fill = .pred_class), alpha = 0.2) + # fill each pixel on the grid base on predicted value
geom_point(data = data, aes(color = y))
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(y ~ x1 + x2, data = data) # two inputs, x1 and x2
glm(y ~ poly(x1, 3) + poly(x2, 3), data = data, family = binomial()) %>%
augment() %>%
glimpse()
mesh <- expand_grid(x1 = seq(-3, 4.5, length.out = 100),
x2 = seq(-3, 4.5, length.out = 100))
# with just linear regression of 2d.
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(y ~ x1 + x2, data = data) %>% # poly to degree 3 is the x^3 function
predict(mesh) %>%
bind_cols(mesh, .) %>%  # attach column of prediction based on x1 and x2 to mesh
ggplot(aes(x1, x2)) +
geom_raster(aes(fill = .pred_class), alpha = 0.2) + # fill each pixel on the grid base on predicted value
geom_point(data = data, aes(color = y))
# with higher dimension factors and predictor
# logistic_reg(mode = "classification") %>%
#   set_engine("glm") %>%
#   fit(y ~ x1 + x2 + poly(x1, 3)+ poly(x2, 3), data = data) %>% # poly to degree 3 is the x^3 function
#   predict(mesh) %>%
#   bind_cols(mesh, .) %>%  # attach column of prediction based on x1 and x2 to mesh
#   ggplot(aes(x1, x2)) +
#     geom_raster(aes(fill = .pred_class), alpha = 0.2) + # fill each pixel on the grid base on predicted value
#     geom_point(data = data, aes(color = y))
vfold_cv(data, 10, strata = y)
rand_forest(mode = "classification") %>%
set_engine("ranger") %>%
fit(y ~ x1 + x2, data = data) %>% # poly to degree 3 is the x^3 function
predict(mesh) %>%
bind_cols(mesh, .) %>%  # attach column of prediction based on x1 and x2 to mesh
ggplot(aes(x1, x2)) +
geom_raster(aes(fill = .pred_class), alpha = 0.2) + # fill each pixel on the grid base on predicted value
geom_point(data = data, aes(color = y))
glimpse(precip)
unique(type)
unique(precip$type)
(waco_precip <- precip %>%
filter(station == "KACT"))
nearby_precip <- precip %>%
filter(station == "KGRK" || station == "KNFW" ||
station == "KFTW" || station == "KDFW" ||
station == "KDAL" || station == "KTYR")
glimpse(nearby_precip)
nearby_precip <- precip %>%
filter(station == "KGRK" || station == "KNFW")  ||
station == "KFTW" || station == "KDFW" ||
station == "KDAL" || station == "KTYR")
nearby_precip <- precip %>%
filter(station == "KGRK" || station == "KNFW")
glimpse(nearby_precip)
nearby_precip <- precip %>%
filter(station %in% c("KGRK", "KNFW", "KFTW", "KDFW",
"KDAL", "KTYR") )
glimpse(nearby_precip)
rf_model <- rand_forest(mode = "classification") %>%
set_engine("ranger") %>%
fit(type ~ data + altitude + temp, data = nearby_precip)  # the first term is what we want to predict
rf_model <- rand_forest(mode = "classification") %>%
set_engine("ranger") %>%
fit(type ~ date + altitude + temp, data = nearby_precip)  # the first term is what we want to predict
rf_model %>%
predict(waco_precip) %>%
bind_cols(waco_precip, .)
predict_result <- rf_model %>%
predict(waco_precip) %>%
bind_cols(waco_precip, .)
rf_model %>%
predict(waco_precip) %>%
bind_cols(waco_precip, .) %>%
conf_mat(type, .pre_class)
rf_model %>%
predict(waco_precip) %>%
bind_cols(waco_precip, .) %>%
conf_mat(type, .pre_class, daa = nearby_precip)
rf_model <- rand_forest(mode = "classification") %>%
set_engine("ranger") %>%
fit(type ~ date + altitude + temp, data = nearby_precip) %>%   # the first term is what we want to predict
predict(waco_precip) %>%
bind_cols(waco_precip, .) %>%
conf_mat(type, .pre_class)
rf_model <- rand_forest(mode = "classification") %>%
set_engine("ranger") %>%
fit(type ~ date + altitude + temp, data = nearby_precip) %>%   # the first term is what we want to predict
predict(waco_precip) %>%
bind_cols(waco_precip, .) %>%
conf_mat(type, .pred_class)
rf_model %>%
predict(waco_precip) %>%
bind_cols(waco_precip, .) %>%
conf_mat(type, .pred_class)
rf_model <- rand_forest(mode = "classification") %>%
set_engine("ranger") %>%
fit(type ~ date + altitude + temp, data = nearby_precip) %>%    # the first term is what we want to predict
predict(waco_precip) %>%
bind_cols(waco_precip, .) %>%
conf_mat(type, .pred_class)
rf_model
rf_model %>%
predict(waco_precip) %>%
bind_cols(waco_precip, .) %>%
conf_mat(type, .pred_class)
rf_model <- rand_forest(mode = "classification") %>%
set_engine("ranger") %>%
fit(type ~ date + altitude + temp, data = nearby_precip)    # the first term is what we want to predict
rf_model %>%
predict(waco_precip) %>%
bind_cols(waco_precip, .) %>%
conf_mat(type, .pred_class)
? rowwise
library("tidyverse"); theme_set(theme_minimal())
theme_update(panel.grid.minor = element_blank())
library("lubridate")
eml_data <- read_csv(
file = "C:/Users/koesl/Documents/Baylor/2020/CSI 2300-01/dataset/EML_through_09_12_2019.csv",
col_types = cols(
"Date-Time" = col_datetime(format = "%m/%d/%y %H:%M"))) %>%
select(-1) %>% # delete col 1
set_names(str_to_lower) %>% # lower case
rename("time" = "date-time") %>%
rename("do_sat" = "dosat")
glimpse(eml_data)
shallow_eml_data <- eml_data %>%
filter(depth <= 1) %>%
mutate(weeks = week(time))
glimpse(shallow_eml_data)
mod_do <- shallow_eml_data %>%
lm(ph~ do, data = .)
summary(mod_do)
mod_do_cond_wk<- shallow_eml_data %>%
lm(ph~do + cond + weeks, data = .)
summary(mod_do_cond_wk)
ggplot(data = shallow_eml_data, aes(x = do, y = ph)) +
geom_point(alpha = 0.25)
ggplot(data = shallow_eml_data, aes(x = cond, y = ph)) +
geom_point(alpha = 0.25)
#Note: similar result even
ggplot(data = shallow_eml_data, aes(x = weeks, y = ph)) +
geom_point(alpha = 0.25)
data_predict <- tibble(cond = c(340, 340),
do = c(7, 7),
weeks = c(37, 38)) %>%
predict(mod_do_cond_wk, .)
#also works:
# new.data<-tibble(cond=c(340,340), do=c(7,7), week=c(37,38))
# mod_do_cond_wk %>% predict(new.data)
library("tidymodels")
# augment(mod_do) # the .fitted is the yhat, or the predicted value.
# note: what this shows is that the mod_do itself carries the data to recreate the model
mod_do %>%
augment() %>%
ggplot(aes(x = do, y = ph)) +
geom_point() +
geom_line(aes(x = do, y = .fitted), color = "blue") # regression line of the predicted model
mod_do %>%
augment() %>%
ggplot(aes(x = do, y = .resid)) +
geom_point(aes(color = shallow_eml_data$weeks))
set.seed(5)
n <- 100
df1 <- MASS::mvrnorm(50, c(0, 0), diag(2)) %>%
as.data.frame() %>% as_tibble() %>%
set_names(c("x1", "x2")) %>%
mutate("y" = 0)
df2 <- MASS::mvrnorm(40, c(1.5, 1.5), diag(2)) %>%
as.data.frame() %>% as_tibble() %>%
set_names(c("x1", "x2")) %>%
mutate("y" = 1)
df3 <- MASS::mvrnorm(10, c(-2, 0), .25*diag(2)) %>%
as.data.frame() %>% as_tibble() %>%
set_names(c("x1", "x2")) %>%
mutate("y" = 1)
(data <- bind_rows(df1, df2, df3) %>%
mutate(y = factor(y)))
ggplot(data, aes(x1, x2, color = y))+
geom_point(size = 3)
expand_grid(x1 = 1:2, x2 = 3:4)
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(y ~ x1 + x2, data = data) # two inputs, x1 and x2
glm(y ~ poly(x1, 3) + poly(x2, 3), data = data, family = binomial()) %>%
augment() %>%
glimpse()
mesh <- expand_grid(x1 = seq(-3, 4.5, length.out = 100),
x2 = seq(-3, 4.5, length.out = 100))
# with just linear regression of 2d.
logistic_reg(mode = "classification") %>%
set_engine("glm") %>%
fit(y ~ x1 + x2, data = data) %>% # poly to degree 1
predict(mesh) %>%
bind_cols(mesh, .) %>%  # attach column of prediction based on x1 and x2 to mesh
ggplot(aes(x1, x2)) +
geom_raster(aes(fill = .pred_class), alpha = 0.2) + # fill each pixel on the grid base on predicted value
geom_point(data = data, aes(color = y))
# with higher dimension factors and predictor
# logistic_reg(mode = "classification") %>%
#   set_engine("glm") %>%
#   fit(y ~ x1 + x2 + poly(x1, 3)+ poly(x2, 3), data = data) %>% # poly to degree 3 is the x^3 function
#   predict(mesh) %>%
#   bind_cols(mesh, .) %>%
#   ggplot(aes(x1, x2)) +
#     geom_raster(aes(fill = .pred_class), alpha = 0.2) +
#     geom_point(data = data, aes(color = y))
rand_forest(mode = "classification") %>%
set_engine("ranger") %>%
fit(y ~ x1 + x2, data = data) %>%
predict(mesh) %>%
bind_cols(mesh, .) %>%
ggplot(aes(x1, x2)) +
geom_raster(aes(fill = .pred_class), alpha = 0.2) +
geom_point(data = data, aes(color = y))
precip <- read_rds("C:/Users/koesl/Documents/Baylor/2020/CSI 2300-01/dataset/precip-precip.rds")
glimpse(precip)
waco_precip <- precip %>%
filter(station == "KACT")
glimpse(waco_precip)
nearby_precip <- precip %>%
filter( station %in% c("KGRK", "KNFW", "KFTW", "KDFW",
"KDAL", "KTYR") )
glimpse(nearby_precip)
waco_precip <- precip %>%
filter(station == "KACT")
glimpse(waco_precip)
nearby_precip <- precip %>%
filter( station %in% c("KGRK", "KNFW", "KFTW", "KDFW",
"KDAL", "KTYR") )
glimpse(nearby_precip)
library("tidyverse"); theme_set(theme_minimal())
theme_update(panel.grid.minor = element_blank())
set.seed(1)
# set sample size
n <- 51
# set true regression parameters
be_0  <- 3
be_1  <- -2
sigma <- .75
# set true f
f <- function(x) be_0 + be_1*x
# make tibble
data <- tibble(
x = seq(0, 5, length.out = n),
y = f(x) + rnorm(n, mean = 0, sd = sigma)
)
data
ggplot(data, aes(x, y)) +
geom_point()
# fit the model
(mod <- lm(y ~ x, data = data))
# compute quantities associated with the model
coef(mod)          # as vector, coefficients, close to be_0 = 3, be_1 = -2
resid(mod)         # e_i's; residuals
fitted.values(mod) # yhat_i's
(RSS <- sum(resid(mod)^2)) # residual sum of squares
(MSE <- RSS / (n-2)) # mean square error, 2 for 2 betas
(RMSE <- sqrt(MSE))  # root mean square error, aka residual standard error, close to sigma = .75
# compute a statistical summary of the model
summary(mod)
load("goodyearMoWater.rda" )
ls()
library( lubridate)
library( viridis)
library( scales)
suppressMessages(library( fields))
load("clean/goodyearMoWater.rda" )
load("~/clean/goodyearMoWater.rda" )
load("../clean/goodyearMoWater.rda" )
dir
dir()
wd()
getwd()
#setwd("~/Dropbox/Home/Projects/Goodyear")
setwd("Baylor/MoWater/proj6/MoWater-Goodyear")
load("clean/goodyearMoWater.rda" )
View(Bin1)
View(Bin1)
library( tidyverse)
install.packages(c("backports", "bayesplot", "dbplyr", "dplyr", "ellipsis", "ggplot2", "glue", "hardhat", "haven", "httpuv", "later", "lubridate", "modelr", "parsnip", "pkgbuild", "pkgload", "ps", "RcppParallel", "reticulate", "rmarkdown", "rsample", "scales", "slider", "sp", "SQUAREM", "StanHeaders", "tidyr", "tidyselect", "tinytex", "vctrs", "xfun"))
install.packages(c("backports", "bayesplot", "dbplyr", "dplyr", "ellipsis", "ggplot2", "glue", "hardhat", "haven", "httpuv", "later", "lubridate", "modelr", "parsnip", "pkgbuild", "pkgload", "ps", "RcppParallel", "reticulate", "rmarkdown", "rsample", "scales", "slider", "sp", "SQUAREM", "StanHeaders", "tidyr", "tidyselect", "tinytex", "vctrs", "xfun"))
install.packages(c("backports", "bayesplot", "dbplyr", "dplyr", "ellipsis", "ggplot2", "glue", "hardhat", "haven", "httpuv", "later", "lubridate", "modelr", "parsnip", "pkgbuild", "pkgload", "ps", "RcppParallel", "reticulate", "rmarkdown", "rsample", "scales", "slider", "sp", "SQUAREM", "StanHeaders", "tidyr", "tidyselect", "tinytex", "vctrs", "xfun"))
load("clean/goodyearMoWater.rda" )
ls()
library( lubridate)
library( viridis)
library( scales)
library( tidyverse)
suppressMessages(library( fields))
head(goodyear)
dfData <- as_tibble(goodyear)
glimpse(dfData)
dfData$Selenium
dfDataC <- dfData[!is.na(dfData$Selenium)]
is.na(dfData$Selenium)
dfDataC <- dfData[!is.na(dfData$Selenium), ]
dfDataC
glimpse(dfDataC)
View(dfDataC)
View(dfDataC)
View(Bin4)
View(Brine)
View(Brine)
View(dfDataC)
View(dfDataC)
dfDataC %>%
select_if(is.numeric) %>% # only compare to numeric
cor() %>% # if we stop here, we'd see the correlation matrix
ggcorrplot::ggcorrplot(method = "circle",
colors = viridis(3), tl.cex =10) +
theme(text = element_text(size = 12),
axis.text.x = element_text(angle=75, hjust=1)) +
expand_limits(x = c(5, 5), y=c(0.0, 10.0))
dfDataC %>%
# select_if(is.numeric) %>% # only compare to numeric
cor() %>% # if we stop here, we'd see the correlation matrix
ggcorrplot::ggcorrplot(method = "circle",
colors = viridis(3), tl.cex =10) +
theme(text = element_text(size = 12),
axis.text.x = element_text(angle=75, hjust=1)) +
expand_limits(x = c(5, 5), y=c(0.0, 10.0))
colnames(dfDataC)
for(i in colnames(dfDataC)){
cur_plot <- ggplot(data = dfDataC, aes_string(x = i, y = "Selenium")) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color = "orange") +
geom_point(alpha = 0.3) +
geom_smooth(method = lm, color = "blue")
print(cur_plot) # autoprint is turned off so we need to print it
#Sys.sleep(2) #sleep so that we can see the output if needed
}
View(dfDataC)
View(dfDataC)
cur_plot <- ggplot(data = dfDataC, aes(x = TDS, y = Selenium)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color = ID ) +
geom_point(alpha = 0.3) +
geom_smooth(method = lm, color = "blue")
cur_plot <- ggplot(data = dfDataC, aes(x = TDS, y = Selenium)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color = dfDataC$ID ) +
geom_point(alpha = 0.3) +
geom_smooth(method = lm, color = "blue")
cur_plot
ggplot(data = dfDataC, aes(x = TDS, y = Selenium)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color = dfDataC$ID ) +
geom_point(alpha = 0.3)
ggplot(data = dfDataC, aes(x = TDS, y = Selenium)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color = dfDataC$ID )
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line( )
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line( color = viridis())
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line( color = viridis())
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line( )
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line( ) +
geom_point(alpha = 0.3)
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis()) +
geom_point(alpha = 0.3)
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis(10)) +
geom_point(alpha = 0.3)
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis(3)) +
geom_point(alpha = 0.3)
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis(539)) +
geom_point(alpha = 0.3)
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis(539))
ggplot(data = dfDataC, aes(x = TDS, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis(539))
ggplot(data = dfDataC, aes(x = date, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis(539))
ggplot(data = dfDataC, aes(x = date, y = Selenium, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis(539)) +
guides(color=guide_legend(keywidth = 3, keyheight = 1))
ggplot(data = dfDataC, aes(x = date, y = TDS, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis(539))
ggplot(data = dfDataC, aes(x = date, y = Arsenic, group=ID, color = ID)) + #aes_string because variable is not actual column factor term, but a name as string.
geom_line(color=viridis(539))
